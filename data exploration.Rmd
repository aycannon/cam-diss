---
title: "Dissertation Code v1"
author: "Archie C"
date: "2025-05-22"
output: html_document
---

```{r preamble, include=FALSE, message=FALSE, warning=FALSE}
source("preamble.R")
```


```{r Data Import}
df <- read_xlsx("data/data1.xlsx")
dt <- as.data.table(df)
```

```{r wide format}
data <- df %>%
    mutate(Base = gsub("=", "", Inst))

wide <- data %>%
    distinct() %>% # there are duplicates, but they are perfect duplicates so we take the distinct values
    dplyr::select(Base, Date, Mid) %>%
    pivot_wider(names_from = Base, values_from = Mid) %>%
    arrange(Date) %>%
    mutate(across(-Date, log))
# everything has been logged as we work in log(spot) and log(forward)
# now we need s_{t+1}

spot_lagged <- wide %>%
  transmute(Date = Date %m+% months(1),  # shift date back by 1 month to align with t
            GBP_t1 = GBP,
            EUR_t1 = EUR,
            JPY_t1 = JPY,
            CAD_t1 = CAD,
            GBP_FWD = GBP1MV,
            EUR_FWD = EUR1MV,
            JPY_FWD = JPY1MV,
            CAD_FWD = CAD1MV)

wide_data <- wide %>%
    inner_join(spot_lagged, by = "Date") %>%
    mutate(GBP_excess = GBP - GBP_t1,
           EUR_excess = EUR - EUR_t1,
           JPY_excess = JPY - JPY_t1,
           CAD_excess = CAD - CAD_t1,
           GBP_prem = GBP_FWD - GBP_t1,
           EUR_prem = EUR_FWD - EUR_t1,
           JPY_prem = JPY_FWD - JPY_t1,
           CAD_prem = CAD_FWD - CAD_t1)

```



```{r initial regressions}
lm(GBP_excess ~ GBP_prem, data = wide_data) %>% summary()
lm(EUR_excess ~ EUR_prem, data = wide_data) %>% summary()
lm(JPY_excess ~ JPY_prem, data = wide_data) %>% summary()
lm(CAD_excess ~ CAD_prem, data = wide_data) %>% summary()
```


```{r data vis}

long_spot <- wide %>%
  dplyr::select(Date, GBP, EUR, CAD) %>%  # drop JPY here
  pivot_longer(cols = -Date, names_to = "Base", values_to = "Spot")

long_prem <- wide_data %>%
  dplyr::select(Date, GBP_prem, EUR_prem, CAD_prem, JPY_prem) %>%  # drop JPY here
  pivot_longer(cols = -Date, names_to = "Base", values_to = "Prem")

ggplot(long_spot, aes(x = Date, y = Spot, color = Base)) +
    geom_line() +
    labs(title = "Spot Rates",
         x = "Date",
         y = "Premium") +
    theme_minimal() +
    scale_color_manual(values = c("blue", "red", "green", "purple")) +
    theme(legend.position = "bottom")

ggplot(long_prem, aes(x = Date, y = Prem)) +
    geom_line(aes(color = Base)) +
    labs(title = "Forward Premium",
         x = "Date",
         y = "Premium") +
    theme_minimal() +
    scale_color_manual(values = c("blue", "red", "green", "purple")) +
    theme(legend.position = "bottom")
```


```{r simple regression to check on the forward premium bias}
currencies <- c("GBP", "EUR", "CAD", "JPY")

# Construct tidy summary for each currency
simple <- map_dfr(currencies, function(cur) {
  excess_var <- paste0(cur, "_excess")
  prem_var <- paste0(cur, "_prem")
  
  data_cur <- wide_data %>%
    dplyr::select(all_of(c(excess_var, prem_var))) %>%
    filter(!is.na(.data[[excess_var]]), !is.na(.data[[prem_var]]))
  
  model <- lm(as.formula(paste0(excess_var, " ~ ", prem_var)), data = data_cur)
  tidy(model) %>% mutate(Currency = cur)
})

for (base in currencies) {
  cat("--------------", base , "--------------\n")
  
  excess_var <- paste0(base, "_excess")
  prem_var <- paste0(base, "_prem")
  
  # Keep only relevant rows with no NA
  df <- wide_data %>%
    dplyr::select(Date, all_of(c(excess_var, prem_var))) %>%
    filter(!is.na(.data[[excess_var]]), !is.na(.data[[prem_var]]))
  
  # Dynamically construct the formula
  f <- as.formula(paste0(excess_var, " ~ ", prem_var))
  m <- lm(f, data = df)
  
  cat("  alpha:", round(coef(m)[1], 4), 
      " | beta:", round(coef(m)[2], 4), "\n")
  
  # Run hypothesis test: H0: beta = 1
  print(linearHypothesis(m, paste0(prem_var, " = 1")))
}
```


So we have found recreated some of the results. We see that in the case of Canada, the result is not statistically different from 1, but in the case of the other currencies, we see that the forward premium is statistically significantly different from 1. This is consistent with the findings in the literature.

```{r plot of coefficients from simple regression}
ggplot(
  simple %>% filter(grepl("_prem$", term)),
  aes(x = Currency, y = estimate)
) +
  geom_pointrange(aes(ymin = estimate - std.error, ymax = estimate + std.error),
                  position = position_dodge(width = 0.5), 
                  color = "steelblue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
  labs(title = "Forward Premium Coefficients",
       x = "Currency",
       y = expression(beta~"Estimate")) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

### Estimating the asymmetric loss function

```{r estimating the loss functions}
p <- 2

gmm_moments <- function(theta, data) {
  alpha <- theta[1]
  e <- data$forecast_error
  z <- as.matrix(data[, c("const", "lag_error")])
  lambda <- alpha + (1 - 2 * alpha) * (e < 0)
  g <- lambda * e^(p - 1) * z
  return(g)
}

for (cur in currencies) {
  message("Running GMM for ", cur)

  # Get wide-format forecast error
  e_col <- cur
  f_col <- paste0(cur, "_FWD")
  
  data_cur <- wide_data %>%
    transmute(
      forecast_error = .data[[e_col]] - .data[[f_col]],
      lag_error = lag(.data[[e_col]] - .data[[f_col]]),
      const = 1
    ) %>%
    na.omit()

  if (nrow(data_cur) > 10) {
    res <- tryCatch({
      gmm(g = gmm_moments,
          x = data_cur,
          t0 = c(0.5),
          type = "cue",
          method = "Brent",
          lower = 0.01,
          upper = 0.99)
    }, error = function(e) NULL)

    if (!is.null(res)) {
      alpha_hat <- coef(res)
      vcv_hat <- vcov(res)
      se_alpha <- sqrt(vcv_hat[1, 1])
      t_stat <- (alpha_hat - 0.5) / se_alpha
      p_val <- 2 * pt(-abs(t_stat), df = nrow(data_cur) - 1)

      currency_results[[cur]] <- list(
        summary = summary(res),
        alpha = alpha_hat,
        vcov = vcv_hat,
        t_stat = t_stat,
        p_val = p_val
      )
    }
  } else {
    message("Not enough data for ", cur)
  }
}

# View results for one example currency (e.g., EUR)
print(currency_results[["EUR"]]$summary)
print(currency_results[["EUR"]]$t_stat)
print(currency_results[["EUR"]]$p_val)

# Extract alpha estimates
alphas <- sapply(currency_results, function(x) if (!is.null(x)) x$alpha else NA)
print(alphas)

# Extract p-values for H0: alpha = 0.5
p_vals <- sapply(currency_results, function(x) if (!is.null(x)) x$p_val else NA)
print(p_vals)

```

```{r transform excess returns}
# Clean alpha names
alphas_clean <- setNames(as.numeric(alphas), gsub("\\.Theta\\[1\\]", "", names(alphas)))

df2 <- df1 %>%
  group_by(Base) %>%
  mutate(
    transformed_excess = if (!Base[1] %in% names(alphas_clean)) {
      NA_real_
    } else {
      alpha <- alphas_clean[[Base[1]]]
      (alpha + (1 - 2 * alpha) * (excess < 0)) * abs(excess)^2
    }
  ) %>%
  ungroup()

simple2 <- df2 %>%
    group_by(Base) %>%
    do(tidy(lm(transformed_excess ~ prem, data = .))) %>%
    ungroup()

for (base in currencies){
    cat("--------------", base , "--------------")
    m <- lm(transformed_excess ~ prem, data = df2 %>% filter(Base == base))
    cat("\n alpha:", round(coef(m)[1], 4), 
        " | beta:", round(coef(m)[2], 4), "\n")
    #print(coef(m))
    print(linearHypothesis(m, "prem = 1"))
}


```


```{r initial qr}

quantiles <- c(0.25, 0.5, 0.75, 0.9)
qr_res <- data.frame()

for (base in currencies){
    cat("--------------", base , "--------------")
    d <- df1 %>% filter(Base == base)
    
    for (tau in quantiles){
    cat("\nQuantile: ", tau, "\n")
    q <- rq(excess ~ prem, data = d, tau = tau)
    s <- summary(q, se = "boot", R = 500)
    
    coef_est <- s$coefficients["prem", "Value"]
    coef_se <- s$coefficients["prem", "Std. Error"]
    
    
    # One sided test: H0: beta >= 1, H1: beta < 1
    z <- (coef_est - 1) / coef_se
    p <- pnorm(z)
    
    qr_res <- rbind(qr_res, data.frame(
      Base = base,
      Tau = tau,
      Estimate = coef_est,
      StdError = coef_se,
      Z = z,
      Pvalue = p
    ))
    
    cat("  Estimate:", round(coef_est, 4), 
        " | SE:", round(coef_se, 4),
        " | z:", round(z, 2),
        " | p-value (H0: beta >= 1):", round(p, 4), "\n\n")
    }
}
```



```{r quantile regression}
# Assuming `alphas` is a named numeric vector like:
# alphas <- c("CAD.Theta[1]" = 0.03, "EUR.Theta[1]" = 0.427, ...)


qr_res_opt <- data.frame()

for (base in currencies) {
  cat("--------------", base , "--------------\n")
  
  d <- df1 %>% filter(Base == base)
  
  # Extract corresponding alpha (round name matching for robustness)
  alpha_tau <- alphas[grep(base, names(alphas), ignore.case = TRUE)]
  
  if (length(alpha_tau) == 0) {
    warning("No alpha found for base: ", base)
    next
  }
  
  tau <- as.numeric(alpha_tau)
  cat("Quantile (alpha-derived): ", tau, "\n")
  
  # Run quantile regression at behaviourally motivated tau
  q <- rq(excess ~ prem, data = d, tau = tau)
  s <- summary(q, se = "boot", R = 500)
  
  coef_est <- s$coefficients["prem", "Value"]
  coef_se <- s$coefficients["prem", "Std. Error"]
  
  # One-sided test: H0: beta >= 1, H1: beta < 1
  z <- (coef_est - 1) / coef_se
  p <- pnorm(z)
  
  qr_res_opt <- rbind(qr_res, data.frame(
    Base = base,
    Tau = tau,
    Estimate = coef_est,
    StdError = coef_se,
    Z = z,
    Pvalue = p
  ))
  
  cat("  Estimate:", round(coef_est, 4), 
      " | SE:", round(coef_se, 4),
      " | z:", round(z, 2),
      " | p-value (H0: beta >= 1):", round(p, 4), "\n\n")
}


```

```{r}
ggplot(qr_res, aes(x = Tau, y = Estimate, color = Base)) +
  geom_line() +
  geom_point() +
  geom_errorbar(aes(ymin = Estimate - 1.96 * StdError,
                    ymax = Estimate + 1.96 * StdError),
                width = 0.02) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "grey") +
  labs(title = "Quantile Regression Estimates of Forward Premium Coefficient",
       x = "Quantile (τ)", y = "Estimate of β (prem)") +
  theme_minimal()

```



```{r quantile forests}
# install.packages("quantregForest")
# library(quantregForest)
df_gbp <- df1 %>% filter(Base == "GBP")

qrf_gbp <- quantregForest(x = data.frame(df_gbp$prem), 
                          y = df_gbp$excess,
                          nthreads = 4,
                          ntree = 1000, nodesize = 5)

print(qrf_gbp)

preds <- predict(qrf_gbp, newdata = data.frame(prem = df_gbp$prem), what = c(0.1, 0.5, 0.9))



```


```{r}
kt_value <- function(r, alpha = 0.88, lambda = 2.25) {
  ifelse(r >= 0, r^alpha, -lambda * (-r)^alpha)
}



df2 <- df1 %>%
    mutate(pt = kt_value(excess))

# plot excess returns vs pt
ggplot(df2, aes(x = excess, y = pt)) +
    geom_point(aes(color = Base), alpha = 0.5) +
    labs(title = "Excess Returns vs. Prospect Theory",
         x = "Excess Returns",
         y = "pt") +
    theme_minimal() +
    scale_color_manual(values = c("blue", "red", "green", "purple")) +
    theme(legend.position = "bottom")

```

```{r}

tune_pt_params_rolling <- function(data, alphas, lambdas, window_size = 60, horizon = 1) {
  param_grid <- expand.grid(alpha = alphas, lambda = lambdas)
  results <- data.frame()
  
  n <- nrow(data)
  max_start <- n - window_size - horizon + 1
  
  pb <- progress_bar$new(
    format = "  tuning [:bar] :percent eta: :eta",
    total = nrow(param_grid), clear = FALSE, width = 60
  )
  
  for (i in 1:nrow(param_grid)) {
    alpha <- param_grid$alpha[i]
    lambda <- param_grid$lambda[i]
    rmse_vec <- c()
    
    for (start in 1:max_start) {
      train_idx <- start:(start + window_size - 1)
      test_idx <- (start + window_size):(start + window_size + horizon - 1)
      
      train <- data[train_idx, ]
      test <- data[test_idx, ]
      
      model <- lm(kt_value(excess, alpha, lambda) ~ prem, data = train)
      preds <- predict(model, newdata = test)
      y_true <- kt_value(test$excess, alpha, lambda)
      rmse <- sqrt(mean((y_true - preds)^2))
      
      rmse_vec <- c(rmse_vec, rmse)
    }
    
    results <- rbind(results, data.frame(alpha, lambda, RMSE = mean(rmse_vec)))
    pb$tick()
  }
  
  best <- results[which.min(results$RMSE), ]
  return(list(best_params = best, full_results = results))
}


```

```{r Tuning value functions}
df_gbp <- df1 %>% filter(Base == "GBP")

alphas <- seq(0.5, 1.0, by = 0.05)
lambdas <- seq(0, 5.0, by = 0.25)

tuned <- tune_pt_params_rolling(df_gbp, alphas, lambdas)
best_params <- tuned$best_params

print(best_params)

```

```{r}


plot_value_function <- function(alphas = c(0.5, 0.88), lambdas = c(1, 2.25, 5), x_range = c(-2, 2)) {
  x_vals <- seq(x_range[1], x_range[2], length.out = 500)
  plot_data <- expand.grid(x = x_vals, alpha = alphas, lambda = lambdas)
  plot_data$value <- mapply(kt_value, plot_data$x, plot_data$alpha, plot_data$lambda)
  plot_data$label <- paste0("α=", plot_data$alpha, ", λ=", plot_data$lambda)
  
  ggplot(plot_data, aes(x = x, y = value, color = label)) +
    geom_line() +
    labs(
      title = "Prospect Theory Value Function",
      x = "Excess Return (x)",
      y = "Transformed Value v(x)",
      color = "Parameters"
    ) +
    theme_minimal()
}

# Example usage:
plot_value_function()

```




