Spot    = mean(Spot, na.rm = TRUE),
Forward = mean(Forward, na.rm = TRUE),
.groups = "drop"
)
monthly_data <- data %>%
mutate(YearMonth = floor_date(Date, "month")) %>%
filter(Type %in% c("Spot", "Forward")) %>%
group_by(YearMonth, Base, Type) %>%
summarise(Value = mean(Value, na.rm = TRUE), .groups = "drop") %>%
pivot_wider(names_from = Type, values_from = Value)
data %>%
mutate(YearMonth = floor_date(Date, "month")) %>%
filter(Type %in% c("Spot", "Forward")) %>%
group_by(YearMonth, Base, Type)
data %>%
mutate(YearMonth = floor_date(Date, "month"))
data %>%
mutate(YearMonth = floor_date(Date, "month")) %>%
filter(Type %in% c("Spot", "Forward"))
data %>%
mutate(YearMonth = floor_date(Date, "month")) %>%
filter(Type %in% c("spot", "Forward"))
floor_date(Date, "month")) %>%
data %>%
mutate(YearMonth = floor_date(Date, "month")) %>%
filter(Type %in% c("spot", "forward"))
data %>%
mutate(YearMonth = floor_date(Date, "month")) %>%
filter(Type %in% c("spot", "forward")) %>%
group_by(YearMonth, Base, Type)
monthly_data <- data %>%
mutate(YearMonth = floor_date(Date, "month")) %>%
filter(Type %in% c("spot", "forward")) %>%
group_by(YearMonth, Base, Type) %>%
summarise(Value = mean(Value, na.rm = TRUE), .groups = "drop") %>%
pivot_wider(names_from = Type, values_from = Value)
monthly_data <- data %>%
mutate(YearMonth = floor_date(Date, "month")) %>%
filter(Type %in% c("spot", "forward")) %>%
group_by(YearMonth, Base, Type) %>%
summarise(Mid = mean(Mid, na.rm = TRUE), .groups = "drop") %>%
pivot_wider(names_from = Type, values_from = Mid)
monthly_data
data %>%
mutate(YearMonth = floor_date(Date, "month")) %>%
filter(Type %in% c("spot", "forward"))
data %>%
mutate(YearMonth = floor_date(Date, "month")) %>%
mutate(Currency = gsub("=|1MV", "", Instrument))
monthly_data <- data %>%
mutate(YearMonth = floor_date(Date, "month")) %>%
mutate(Currency = gsub("|1MV", "", Base)) %>%
filter(Type %in% c("spot", "forward")) %>%
group_by(YearMonth, Currency, Type) %>%
summarise(Mid = mean(Mid, na.rm = TRUE), .groups = "drop") %>%
pivot_wider(names_from = Type, values_from = Mid)
monthly_data
monthly_data <- data %>%
mutate(YearMonth = floor_date(Date, "month")) %>%
mutate(Currency = gsub("|1MV", "", Base)) %>%
filter(Type %in% c("spot", "forward")) %>%
group_by(YearMonth, Currency, Type) %>%
summarise(Mid = mean(Mid, na.rm = TRUE), .groups = "drop") %>%
pivot_wider(names_from = Type, values_from = Mid) %>%
mutate(across(c(forward, spot), log))
monthly_data
wide_month <- monthly_data %>%
pivot_wider(names_from = Currency, values_from = c(spot, forward), names_sep = "_") %>%
arrange(YearMonth)
wide_month
# Create lagged spot values to compute excess returns
spot_lagged_month <- wide_month %>%
transmute(
YearMonth = YearMonth %m+% months(1),
spot_GBP_t1 = spot_GBP,
spot_EUR_t1 = spot_EUR,
spot_JPY_t1 = spot_JPY,
spot_CAD_t1 = spot_CAD
)
# Merge and compute returns
wide_month <- wide_month %>%
inner_join(spot_lagged_month, by = "YearMonth") %>%
mutate(
GBP_excess = spot_GBP_t1 - spot_GBP,
EUR_excess = spot_EUR_t1 - spot_EUR,
JPY_excess = spot_JPY_t1 - spot_JPY,
CAD_excess = spot_CAD_t1 - spot_CAD,
GBP_prem   = forward_GBP - spot_GBP,
EUR_prem   = forward_EUR - spot_EUR,
JPY_prem   = forward_JPY - spot_JPY,
CAD_prem   = forward_CAD - spot_CAD
)
wide_month
for (cur in currencies) {
excess_var <- paste0(cur, "_excess")
prem_var   <- paste0(cur, "_prem")
df <- wide_data %>%
select(all_of(c(excess_var, prem_var))) %>%
filter(!is.na(.data[[excess_var]]), !is.na(.data[[prem_var]]))
# Fit linear model
model <- lm(as.formula(paste0(excess_var, " ~ ", prem_var)), data = df)
# Classical SEs
model_summary <- summary(model)
SE_classical <- model_summary$coefficients[, "Std. Error"]
# Newey-West SEs (lag = 14)
nw_vcov <- NeweyWest(model, lag = 14, prewhite = FALSE)
nw_se   <- coeftest(model, vcov. = nw_vcov)
# Save stats
summary_stats <- tibble(
Currency     = cur,
Intercept    = coef(model)[1],
SE_Intercept = SE_classical[1],
SE_NW_Intercept = nw_se[1, 2],
Slope        = coef(model)[2],
SE_Slope     = SE_classical[2],
SE_NW_Slope  = nw_se[2, 2],
R2           = model_summary$r.squared,
AIC          = AIC(model),
BIC          = BIC(model),
N            = nobs(model)
)
# Residuals and fitted values
residuals_df <- tibble(
Currency = cur,
Fitted   = fitted(model),
Residual = resid(model)
)
# Store everything
lm_data_monthly[[cur]] <- list(
model       = model,
summary     = summary_stats,
residuals   = residuals_df
)
}
lm_data_monthly <- list()
for (cur in currencies) {
excess_var <- paste0(cur, "_excess")
prem_var   <- paste0(cur, "_prem")
df <- wide_data %>%
dplyr::select(all_of(c(excess_var, prem_var))) %>%
filter(!is.na(.data[[excess_var]]), !is.na(.data[[prem_var]]))
# Fit linear model
model <- lm(as.formula(paste0(excess_var, " ~ ", prem_var)), data = df)
# Classical SEs
model_summary <- summary(model)
SE_classical <- model_summary$coefficients[, "Std. Error"]
# Newey-West SEs (lag = 14)
nw_vcov <- NeweyWest(model, lag = 14, prewhite = FALSE)
nw_se   <- coeftest(model, vcov. = nw_vcov)
# Save stats
summary_stats <- tibble(
Currency     = cur,
Intercept    = coef(model)[1],
SE_Intercept = SE_classical[1],
SE_NW_Intercept = nw_se[1, 2],
Slope        = coef(model)[2],
SE_Slope     = SE_classical[2],
SE_NW_Slope  = nw_se[2, 2],
R2           = model_summary$r.squared,
AIC          = AIC(model),
BIC          = BIC(model),
N            = nobs(model)
)
# Residuals and fitted values
residuals_df <- tibble(
Currency = cur,
Fitted   = fitted(model),
Residual = resid(model)
)
# Store everything
lm_data_monthly[[cur]] <- list(
model       = model,
summary     = summary_stats,
residuals   = residuals_df
)
}
# Combine all regression summaries into one table
lmresults_df_monthly <- bind_rows(lapply(lm_data_monthly, `[[`, "summary"))
print(lmresults_df_monthly)
wide_month
wide_month_macro <- wide_month %>%
mutate(
int_US = simulate_macro(0.015, 0.002, nrow(wide_month)),
inf_US = simulate_macro(0.02,  0.002, nrow(wide_month)),
gdp_US = simulate_macro(0.025, 0.003, nrow(wide_month))
)
simulate_macro <- function(base, vol, n) {
rnorm(n, mean = base, sd = vol)
}
wide_month_macro <- wide_month %>%
mutate(
int_US = simulate_macro(0.015, 0.002, nrow(wide_month)),
inf_US = simulate_macro(0.02,  0.002, nrow(wide_month)),
gdp_US = simulate_macro(0.025, 0.003, nrow(wide_month))
)
# Simulate for each currency and compute differentials
for (ccy in currencies) {
wide_month_macro[[paste0("int_", ccy)]] <- simulate_macro(0.02, 0.0025, nrow(wide_month))
wide_month_macro[[paste0("inf_", ccy)]] <- simulate_macro(0.025, 0.0025, nrow(wide_month))
wide_month_macro[[paste0("gdp_", ccy)]] <- simulate_macro(0.03, 0.003, nrow(wide_month))
# Compute differentials
wide_month_macro[[paste0("int_diff_", ccy)]] <- wide_month_macro[[paste0("int_", ccy)]] - wide_month_macro$int_US
wide_month_macro[[paste0("inf_diff_", ccy)]] <- wide_month_macro[[paste0("inf_", ccy)]] - wide_month_macro$inf_US
wide_month_macro[[paste0("gdp_diff_", ccy)]] <- wide_month_macro[[paste0("gdp_", ccy)]] - wide_month_macro$gdp_US
}
head(wide_month_macro)
# -------- 0. User inputs --------
# wide_data: Must contain Date, for each currency: XX_excess, XX_FWD, and macro features
# currencies: e.g. c("GBP", "EUR", "JPY", "CAD")
# window: size of rolling GMM window (in months)
# p: power for loss (1 = lin-lin, 2 = quad-quad)
window_m <- 60  # 5 years daily
p <- 2         # quad-quad loss
macro_prefixes <- c() # (optional) if you want to filter macro features by prefix, e.g. c("infl_", "gdp_")
# -------- 1. Identify Macro Features Automatically --------
exclude_patterns <- c("_excess$", "_FWD$", "^Date$", "^date$", "^const$", "^lag_")
macro_features <- names(wide_month_macro)
macro_features
for (pat in exclude_patterns) {
macro_features <- macro_features[!grepl(pat, macro_features)]
}
if (length(macro_prefixes) > 0) {
macro_features <- macro_features[grepl(paste(macro_prefixes, collapse="|"), macro_features)]
}
# Remove any duplicated names just in case
macro_features <- unique(macro_features)
# -------- 2. Rolling GMM Alpha Estimation (Elliott et al. 2006) --------
plan(multisession, workers = parallel::detectCores() - 1)
# -------- 2. Rolling GMM Alpha Estimation (Elliott et al. 2006) --------
library(furrr)
library(dplyr)
library(gmm)
plan(multisession, workers = parallel::detectCores() - 1)
roll_alpha_gmm_parallel <- function(data, currencies, window = 60, p = 2) {
n <- nrow(data)
date_seq <- data$Date[(window + 1):n]
# Inner function for one currency
estimate_alpha_for_currency <- function(cur) {
e_col <- paste0(cur, "_excess")
f_col <- paste0(cur, "_FWD")
alpha_vec <- rep(NA_real_, length(date_seq))
for (i in seq_along(date_seq)) {
idx_start <- i
idx_end <- i + window_m - 1
sub_data <- data[idx_start:idx_end, ]
dat_cur <- sub_data %>%
transmute(
forecast_error = .data[[e_col]] - .data[[f_col]],
lag_error = lag(.data[[e_col]] - .data[[f_col]]),
const = 1
) %>% na.omit()
if (nrow(dat_cur) > 10) {
gmm_moments <- function(theta, data) {
alpha <- theta[1]
e <- data$forecast_error
z <- as.matrix(data[, c("const", "lag_error")])
lambda <- alpha + (1 - 2 * alpha) * (e < 0)
g <- lambda * e^(p - 1) * z
return(g)
}
res <- tryCatch({
gmm(g = gmm_moments, x = dat_cur, t0 = c(0.5),
type = "cue", method = "Brent", lower = 0.01, upper = 0.99)
}, error = function(e) NULL)
alpha_vec[i] <- if (!is.null(res)) coef(res)[1] else NA
}
}
return(alpha_vec)
}
# Run in parallel
alpha_list <- future_map(currencies, estimate_alpha_for_currency, .progress = TRUE)
names(alpha_list) <- currencies
alpha_matrix <- do.call(cbind, alpha_list)
rownames(alpha_matrix) <- as.character(date_seq)
return(alpha_matrix)
}
roll_alpha_gmm_parallel <- function(data, currencies, window = 60, p = 2) {
n <- nrow(data)
date_seq <- data$Date[(window + 1):n]
# Inner function for one currency
estimate_alpha_for_currency <- function(cur) {
e_col <- paste0(cur, "_excess")
f_col <- paste0(cur, "_FWD")
alpha_vec <- rep(NA_real_, length(date_seq))
for (i in seq_along(date_seq)) {
idx_start <- i
idx_end <- i + window - 1
sub_data <- data[idx_start:idx_end, ]
dat_cur <- sub_data %>%
transmute(
forecast_error = .data[[e_col]] - .data[[f_col]],
lag_error = lag(.data[[e_col]] - .data[[f_col]]),
const = 1
) %>% na.omit()
if (nrow(dat_cur) > 10) {
gmm_moments <- function(theta, data) {
alpha <- theta[1]
e <- data$forecast_error
z <- as.matrix(data[, c("const", "lag_error")])
lambda <- alpha + (1 - 2 * alpha) * (e < 0)
g <- lambda * e^(p - 1) * z
return(g)
}
res <- tryCatch({
gmm(g = gmm_moments, x = dat_cur, t0 = c(0.5),
type = "cue", method = "Brent", lower = 0.01, upper = 0.99)
}, error = function(e) NULL)
alpha_vec[i] <- if (!is.null(res)) coef(res)[1] else NA
}
}
return(alpha_vec)
}
# Run in parallel
alpha_list <- future_map(currencies, estimate_alpha_for_currency, .progress = TRUE)
names(alpha_list) <- currencies
alpha_matrix <- do.call(cbind, alpha_list)
rownames(alpha_matrix) <- as.character(date_seq)
return(alpha_matrix)
}
alpha_matrix <- roll_alpha_gmm_parallel(wide_month_macro, currencies, window = window_m, p = p)
alpha_matrix
alpha_matrix
wide_month_macro
wide_month_macro
roll_alpha_gmm_parallel <- function(data, currencies, window = 60, p = 2) {
n <- nrow(data)
date_seq <- data$Date[(window + 1):n]
# Inner function for one currency
estimate_alpha_for_currency <- function(cur) {
e_col <- paste0(cur, "_excess")
f_col <- paste0(cur, "_prem")
alpha_vec <- rep(NA_real_, length(date_seq))
for (i in seq_along(date_seq)) {
idx_start <- i
idx_end <- i + window - 1
sub_data <- data[idx_start:idx_end, ]
dat_cur <- sub_data %>%
transmute(
forecast_error = .data[[e_col]] - .data[[f_col]],
lag_error = lag(.data[[e_col]] - .data[[f_col]]),
const = 1
) %>% na.omit()
if (nrow(dat_cur) > 10) {
gmm_moments <- function(theta, data) {
alpha <- theta[1]
e <- data$forecast_error
z <- as.matrix(data[, c("const", "lag_error")])
lambda <- alpha + (1 - 2 * alpha) * (e < 0)
g <- lambda * e^(p - 1) * z
return(g)
}
res <- tryCatch({
gmm(g = gmm_moments, x = dat_cur, t0 = c(0.5),
type = "cue", method = "Brent", lower = 0.01, upper = 0.99)
}, error = function(e) NULL)
alpha_vec[i] <- if (!is.null(res)) coef(res)[1] else NA
}
}
return(alpha_vec)
}
# Run in parallel
alpha_list <- future_map(currencies, estimate_alpha_for_currency, .progress = TRUE)
names(alpha_list) <- currencies
alpha_matrix <- do.call(cbind, alpha_list)
rownames(alpha_matrix) <- as.character(date_seq)
return(alpha_matrix)
}
alpha_matrix <- roll_alpha_gmm_parallel(wide_month_macro, currencies, window = window_m, p = p)
alpha_matrix
roll_alpha_gmm_parallel <- function(data, currencies, window = 60, p = 2) {
n <- nrow(data)
date_seq <- data$YearMonth[(window + 1):n]
# Inner function for one currency
estimate_alpha_for_currency <- function(cur) {
e_col <- paste0(cur, "_excess")
f_col <- paste0(cur, "_prem")
alpha_vec <- rep(NA_real_, length(date_seq))
for (i in seq_along(date_seq)) {
idx_start <- i
idx_end <- i + window - 1
sub_data <- data[idx_start:idx_end, ]
dat_cur <- sub_data %>%
transmute(
forecast_error = .data[[e_col]] - .data[[f_col]],
lag_error = lag(.data[[e_col]] - .data[[f_col]]),
const = 1
) %>% na.omit()
if (nrow(dat_cur) > 10) {
gmm_moments <- function(theta, data) {
alpha <- theta[1]
e <- data$forecast_error
z <- as.matrix(data[, c("const", "lag_error")])
lambda <- alpha + (1 - 2 * alpha) * (e < 0)
g <- lambda * e^(p - 1) * z
return(g)
}
res <- tryCatch({
gmm(g = gmm_moments, x = dat_cur, t0 = c(0.5),
type = "cue", method = "Brent", lower = 0.01, upper = 0.99)
}, error = function(e) NULL)
alpha_vec[i] <- if (!is.null(res)) coef(res)[1] else NA
}
}
return(alpha_vec)
}
# Run in parallel
alpha_list <- future_map(currencies, estimate_alpha_for_currency, .progress = TRUE)
names(alpha_list) <- currencies
alpha_matrix <- do.call(cbind, alpha_list)
rownames(alpha_matrix) <- as.character(date_seq)
return(alpha_matrix)
}
alpha_matrix <- roll_alpha_gmm_parallel(wide_month_macro, currencies, window = window_m, p = p)
alpha_matrix
date_seq <- as.Date(rownames(alpha_matrix))
n_steps <- length(date_seq)
N_assets <- length(currencies)
# -------- 3. Build Features and Target Arrays for Neural Net --------
F_feats <- length(macro_features) + 2  # fwd prem + alpha + all macro features
X_feats <- array(NA_real_, dim = c(n_steps, N_assets, F_feats),
dimnames = list(time = as.character(date_seq), asset = currencies,
feature = c("fwd_prem", macro_features, "alpha")))
R_next  <- matrix(NA_real_, nrow = n_steps, ncol = N_assets, dimnames = list(as.character(date_seq), currencies))
for (i in seq_len(n_steps)) {
t <- date_seq[i]
t1 <- t %m+% months(1)
row <- wide_month_macro %>% filter(Date == t)
next_row <- wide_month_macro %>% filter(Date == t1)
for (j in seq_along(currencies)) {
cur <- currencies[j]
fwd_prem <- if (!is.null(row[[paste0(cur, "_prem")]]) & !is.null(row[[paste0(cur, "_excess")]])) {
row[[paste0(cur, "_prem")]] - row[[paste0(cur, "_excess")]]
} else { NA_real_ }
macro_vals <- as.numeric(row[1, macro_features, drop = FALSE])
alpha_val <- alpha_matrix[i, cur]
X_feats[i, j, ] <- c(fwd_prem, macro_vals, alpha_val)
R_next[i, j] <- if (nrow(next_row) > 0) next_row[[paste0(cur, "_excess")]] else NA
}
}
for (i in seq_len(n_steps)) {
t <- date_seq[i]
t1 <- t %m+% months(1)
row <- wide_month_macro %>% dplyr::filter(YearMonth == t)
next_row <- wide_month_macro %>% filter(YearMonth == t1)
for (j in seq_along(currencies)) {
cur <- currencies[j]
fwd_prem <- if (!is.null(row[[paste0(cur, "_prem")]]) & !is.null(row[[paste0(cur, "_excess")]])) {
row[[paste0(cur, "_prem")]] - row[[paste0(cur, "_excess")]]
} else { NA_real_ }
macro_vals <- as.numeric(row[1, macro_features, drop = FALSE])
alpha_val <- alpha_matrix[i, cur]
X_feats[i, j, ] <- c(fwd_prem, macro_vals, alpha_val)
R_next[i, j] <- if (nrow(next_row) > 0) next_row[[paste0(cur, "_excess")]] else NA
}
}
# Remove rows where all R_next are NA (no returns to predict)
valid_idx <- which(!apply(is.na(R_next), 1, all))
X_feats_final     <- X_feats[valid_idx, , , drop = FALSE]
R_next_final      <- R_next[valid_idx, , drop = FALSE]
train_dates_final <- date_seq[valid_idx]
# Optional: Remove rows where ANY macro feature is NA
good_rows <- sapply(seq_len(dim(X_feats_final)[1]), function(i) !any(is.na(X_feats_final[i, , ])))
X_feats_final     <- X_feats_final[good_rows, , , drop = FALSE]
R_next_final      <- R_next_final[good_rows, , drop = FALSE]
train_dates_final <- train_dates_final[good_rows]
# -------- 4. Keras Deep PPP Model Definition --------
F_feats <- dim(X_feats_final)[3]
N_assets <- dim(X_feats_final)[2]
asset_net <- keras_model_sequential(name = 'asset_net') %>%
layer_dense(units = 32, kernel_regularizer = regularizer_l2(1e-4), input_shape = c(F_feats)) %>%
layer_activation_leaky_relu(alpha = 0.01) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 16, kernel_regularizer = regularizer_l2(1e-4)) %>%
layer_activation_leaky_relu(alpha = 0.01) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear', kernel_regularizer = regularizer_l2(1e-4))
library(keras)
asset_net <- keras_model_sequential(name = 'asset_net') %>%
layer_dense(units = 32, kernel_regularizer = regularizer_l2(1e-4), input_shape = c(F_feats)) %>%
layer_activation_leaky_relu(alpha = 0.01) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 16, kernel_regularizer = regularizer_l2(1e-4)) %>%
layer_activation_leaky_relu(alpha = 0.01) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear', kernel_regularizer = regularizer_l2(1e-4))
library(reticulate)
asset_net <- keras_model_sequential(name = 'asset_net') %>%
layer_dense(units = 32, kernel_regularizer = regularizer_l2(1e-4), input_shape = c(F_feats)) %>%
layer_activation_leaky_relu(alpha = 0.01) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 16, kernel_regularizer = regularizer_l2(1e-4)) %>%
layer_activation_leaky_relu(alpha = 0.01) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear', kernel_regularizer = regularizer_l2(1e-4))
reticulate::py_config()
reticulate::py_run_string("import tensorflow as tf; print(tf.__version__)")
library(keras)
install_keras(method = "virtualenv", envname = "r-keras", tensorflow = "2.10.0")
reticulate::virtualenv_install(
envname = "r-keras",
packages = "keras==2.11.0",
pip = TRUE
)
reticulate::use_virtualenv("r-keras", required = TRUE)
asset_net <- keras_model_sequential(name = 'asset_net') %>%
layer_dense(units = 32, kernel_regularizer = regularizer_l2(1e-4), input_shape = c(F_feats)) %>%
layer_activation_leaky_relu(alpha = 0.01) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 16, kernel_regularizer = regularizer_l2(1e-4)) %>%
layer_activation_leaky_relu(alpha = 0.01) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 1, activation = 'linear', kernel_regularizer = regularizer_l2(1e-4))
